{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de los datos y limpieza\n",
    "\n",
    "Carga del archivo homicidios.xlsl la tabla VICTIMAS e importar frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import requests\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "file_path = 'homicidios.xlsx'  # Cambia esto por la ruta real del archivo\n",
    "\n",
    "# Cargar las hojas en DataFrames independientes\n",
    "hechos_df = pd.read_excel(file_path, sheet_name='HECHOS')\n",
    "victimas_df = pd.read_excel(file_path, sheet_name='VICTIMAS')\n",
    "\n",
    "# Mostrar las primeras filas de cada DataFrame para verificar su contenido\n",
    "hechos_df.head(), victimas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vista General de los datos del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspección inicial de hechos\n",
    "print(\"Información general de Hechos:\")\n",
    "print(hechos_df.info())\n",
    "print(\"\\nConteo de valores nulos en Hechos:\")\n",
    "print(hechos_df.isnull().sum())\n",
    "\n",
    "# Inspección inicial de víctimas\n",
    "print(\"\\nInformación general de Víctimas:\")\n",
    "print(victimas_df.info())\n",
    "print(\"\\nConteo de valores nulos en Víctimas:\")\n",
    "print(victimas_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deteccion de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar duplicados\n",
    "hechos_duplicados = hechos_df.duplicated().sum()\n",
    "victimas_duplicados = victimas_df.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados en Hechos: {hechos_duplicados}\")\n",
    "print(f\"Duplicados en Victimas: {victimas_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conteo de Valores sin datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sin datos\n",
    "na_counts = victimas_df.isna().sum()\n",
    "print(na_counts)\n",
    "\n",
    "# Dimensiones del DataFrame\n",
    "num_filas, num_columnas = hechos_df.shape\n",
    "print(f\"\\nNúmero de filas: {num_filas}, Número de columnas: {num_columnas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar 'FECHA' y 'HORA' en una nueva columna 'FECHA_HORA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hechos_df['HORA'] = hechos_df['HORA'].replace('SD', '00:00:00')\n",
    "\n",
    "\n",
    "# Verificar si la columna 'HORA' está en formato string y necesita conversión\n",
    "hechos_df['HORA'] = hechos_df['HORA'].apply(lambda x: x if isinstance(x, datetime.time) else pd.to_datetime(x).time())\n",
    "\n",
    "\n",
    "# Combinar 'FECHA' y 'HORA' en una nueva columna 'FECHA_HORA'\n",
    "hechos_df['FECHA_HORA'] = pd.to_datetime(hechos_df['FECHA'].astype(str) + ' ' + hechos_df['HORA'].astype(str), errors='coerce')\n",
    "\n",
    "# Verificar el resultado\n",
    "print(hechos_df[['FECHA', 'HORA', 'FECHA_HORA']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrado = hechos_df.loc[hechos_df['pos x'] == '.']\n",
    "\n",
    "# Mostrar las filas filtradas\n",
    "print(filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las cordenadas en API google y llenar valores de valores con '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener coordenadas usando la API de Google Maps\n",
    "def obtener_coordenadas(direccion, api_key):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={direccion}&key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Verificar si la solicitud fue exitosa y si hay resultados\n",
    "    if data['status'] == 'OK':\n",
    "        location = data['results'][0]['geometry']['location']\n",
    "        return location['lat'], location['lng']  # Retorna latitud y longitud\n",
    "    else:\n",
    "        # Retornar valores nulos si no se puede obtener la dirección\n",
    "        return None, None\n",
    "\n",
    "# Tu clave de API de Google Maps\n",
    "api_key = 'AIzaSyDyVSvFu2wxYivarcLCGU1wYrE51U-CroA'\n",
    "\n",
    "# Iterar sobre las filas del DataFrame original y actualizar 'pos x' y 'pos y'\n",
    "for index, row in hechos_df.iterrows():\n",
    "    if row['pos x'] == '.':  # Solo procesar si 'pos x' es igual a '.'\n",
    "        direccion = row['LUGAR_DEL_HECHO']\n",
    "\n",
    "        if pd.notnull(direccion):  # Solo buscar si la dirección no es nula\n",
    "            lat, lng = obtener_coordenadas(direccion, api_key)\n",
    "            \n",
    "            # Reemplazar los valores en 'pos x' y 'pos y' en el DataFrame original\n",
    "            hechos_df.at[index, 'pos y'] = lat\n",
    "            hechos_df.at[index, 'pos x'] = lng\n",
    "        else:\n",
    "            # Si no hay dirección, dejar los valores actuales\n",
    "            hechos_df.at[index, 'pos x'] = None\n",
    "            hechos_df.at[index, 'pos y'] = None\n",
    "\n",
    "#Se eliminan nos valores nulos \n",
    "hechos_df = hechos_df.dropna(subset=['pos x', 'pos y'])\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(hechos_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar columnas redundantes e innecesarias en hechos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir las columnas a eliminar\n",
    "columnas_a_eliminar = ['AAAA', 'MM', 'DD','HH','Calle','Altura', 'Cruce', 'Dirección Normalizada','XY (CABA)', 'HORA','FECHA','LUGAR_DEL_HECHO']\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "hechos_df = hechos_df.drop(columns=columnas_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores unicos por columna Victima y Acusado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una lista de columnas para las cuales deseas obtener valores únicos\n",
    "columnas_a_consultar = ['VICTIMA', 'CALLE',  'ACUSADO']  # Puedes modificar esta lista\n",
    "\n",
    "# Obtener los valores únicos de las columnas especificadas en hechos_df\n",
    "unique_values = {col: hechos_df[col].unique() for col in columnas_a_consultar if col in hechos_df.columns}\n",
    "\n",
    "# Mostrar los valores únicos para cada columna especificada\n",
    "for column, unique_values in unique_values.items():\n",
    "    print(f\"Valores únicos en la columna '{column}':\\n{unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir las columnas pos x y pos y en tipo float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores no válidos (por ejemplo, \".\") por NaN\n",
    "hechos_df['pos x'] = hechos_df['pos x'].replace('.', np.nan)\n",
    "hechos_df['pos y'] = hechos_df['pos y'].replace('.', np.nan)\n",
    "\n",
    "# Convertir las columnas a tipo numérico (float), forzando el manejo de errores\n",
    "hechos_df['pos x'] = pd.to_numeric(hechos_df['pos x'], errors='coerce')\n",
    "hechos_df['pos y'] = pd.to_numeric(hechos_df['pos y'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los valores nulos en la columna 'FECHA_HORA' del DataFrame 'hechos_df'\n",
    "nulos_fecha_hora = hechos_df['FECHA_HORA'].isnull().sum()\n",
    "valores_nulos_fecha_hora = hechos_df['FECHA_HORA'].isnull()\n",
    "\n",
    "# Mostrar la cantidad de valores nulos y los registros donde están presentes\n",
    "valores_nulos_info = hechos_df[valores_nulos_fecha_hora]\n",
    "\n",
    "nulos_fecha_hora, valores_nulos_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de siniestros por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraer el año de la columna FECHA y crear la nueva columna 'AAAA'\n",
    "hechos_df['AÑO'] = hechos_df['FECHA_HORA'].dt.year\n",
    "\n",
    "# Ejemplo gráfico: cantidad de siniestros por año\n",
    "siniestros_por_ano = hechos_df.groupby('AÑO').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "siniestros_por_ano.plot(kind='bar', color='lightcoral')\n",
    "plt.title('Cantidad de siniestros por año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Número de siniestros')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar columnas redundantes e innecesarias en victimas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas a eliminar\n",
    "columnas_a_eliminar = ['AAAA', 'MM', 'DD','FECHA_FALLECIMIENTO','FECHA']\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "victimas_df = victimas_df.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(victimas_df.head())  # Muestra las primeras filas para confirmar que las columnas fueron eliminadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de Datos en victimas_df y modificacion del formato de Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores \"SD\" en la columna EDAD por 0 \n",
    "victimas_df['EDAD'] = np.where(victimas_df['EDAD'] == 'SD', 0, victimas_df['EDAD'])\n",
    "\n",
    "# Convertir la columna EDAD a tipo numérico\n",
    "victimas_df['EDAD'] = pd.to_numeric(victimas_df['EDAD'], errors='coerce').fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la distribución de la edad de las víctimas\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Creamos un histograma de las edades\n",
    "sns.histplot(victimas_df['EDAD'], bins=15, kde=True, color='skyblue')\n",
    "plt.title('Distribución de la Edad de las Víctimas en Siniestros Viales')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Gráfico para la variable cualitativa 'TIPO_DE_CALLE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la variable cualitativa 'TIPO_DE_CALLE'\n",
    "sns.countplot(data=hechos_df, x='TIPO_DE_CALLE', palette='viridis')\n",
    "plt.title('Cantidad de Siniestros Viales por Tipo de Calle')\n",
    "plt.xlabel('Tipo de Calle')\n",
    "plt.ylabel('Cantidad de Siniestros')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar el DataFrame a un archivo CSV\n",
    "victimas_df.to_csv('victimas_limpio.csv', index=False)\n",
    "hechos_df.to_csv('hechos_limpio.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cambiar el nombre de la columna 'pos x' a 'pos_x'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el nombre de la columna 'pos x' a 'pos_x'\n",
    "hechos_df.rename(columns={'pos x': 'pos_x'}, inplace=True)\n",
    "# Cambiar el nombre de la columna 'pos y' a 'pos_y'\n",
    "hechos_df.rename(columns={'pos y': 'pos_y'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE HECHOS_CV A MYSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno desde el archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Parámetros de conexión desde variables de entorno\n",
    "host = os.getenv('DB_HOST')\n",
    "user = os.getenv('DB_USER')\n",
    "port = os.getenv('DB_PORT')\n",
    "password = os.getenv('DB_PASSWORD')\n",
    "database = os.getenv('DB_NAME')\n",
    "\n",
    "# Crear una conexión a la base de datos utilizando SQLAlchemy\n",
    "connection_string = f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Intentar subir el DataFrame a la tabla 'hechos'\n",
    "try:\n",
    "    hechos_df.to_sql('hechos', con=engine, if_exists='append', index=False)\n",
    "    print(\"Datos de hechos insertados exitosamente.\")\n",
    "\n",
    "    # Verificar si ID_hecho existe en hechos\n",
    "    existing_ids = hechos_df['ID'].unique()  # Obtener IDs existentes en hechos\n",
    "    victimas_df = victimas_df[victimas_df['ID_hecho'].isin(existing_ids)]  # Filtrar victimas_df\n",
    "\n",
    "    # Subir el DataFrame a la tabla 'victimas'\n",
    "    if not victimas_df.empty:\n",
    "        victimas_df.to_sql('victimas', con=engine, if_exists='append', index=False)\n",
    "        print(\"Datos de victimas insertados exitosamente.\")\n",
    "    else:\n",
    "        print(\"No hay datos de victimas para insertar.\");\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Ocurrió un error durante la inserción:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Cerrar la conexión\n",
    "    engine.dispose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer el año de la columna de fechas\n",
    "hechos_df['year'] = hechos_df['FECHA_HORA'].dt.year\n",
    "\n",
    "# Definir la población total (ajustar según datos)\n",
    "poblacion_total = 3120000  \n",
    "\n",
    "# Agrupar por año y contar el número de homicidios en siniestros viales\n",
    "homicidios_por_año = hechos_df.groupby('year')['N_VICTIMAS'].sum()\n",
    "\n",
    "# Calcular la tasa por año\n",
    "tasa_homicidios_por_año = (homicidios_por_año / poblacion_total) * 100000\n",
    "\n",
    "# Mostrar las tasas por año\n",
    "print(\"Tasa de homicidios en siniestros viales por año:\")\n",
    "print(tasa_homicidios_por_año)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga del archivo homicidios.xlsl la tabla VICTIMAS e importar frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "# Cargar el archivo Excel\n",
    "file_path = 'homicidios.xlsx'  # Cambia esto por la ruta real del archivo\n",
    "\n",
    "# Cargar las hojas en DataFrames independientes\n",
    "hechos_df = pd.read_excel(file_path, sheet_name='HECHOS')\n",
    "victimas_df = pd.read_excel(file_path, sheet_name='VICTIMAS')\n",
    "\n",
    "# Mostrar las primeras filas de cada DataFrame para verificar su contenido\n",
    "hechos_df.head(), victimas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vista General de los datos del DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspección inicial de hechos\n",
    "print(\"Información general de Hechos:\")\n",
    "print(hechos_df.info())\n",
    "print(\"\\nConteo de valores nulos en Hechos:\")\n",
    "print(hechos_df.isnull().sum())\n",
    "\n",
    "# Inspección inicial de víctimas\n",
    "print(\"\\nInformación general de Víctimas:\")\n",
    "print(victimas_df.info())\n",
    "print(\"\\nConteo de valores nulos en Víctimas:\")\n",
    "print(victimas_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deteccion de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobar duplicados\n",
    "hechos_duplicados = hechos_df.duplicated().sum()\n",
    "victimas_duplicados = victimas_df.duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados en Hechos: {hechos_duplicados}\")\n",
    "print(f\"Duplicados en Victimas: {victimas_duplicados}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conteo de Valores sin datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sin datos\n",
    "na_counts = victimas_df.isna().sum()\n",
    "print(na_counts)\n",
    "\n",
    "# Dimensiones del DataFrame\n",
    "num_filas, num_columnas = hechos_df.shape\n",
    "print(f\"\\nNúmero de filas: {num_filas}, Número de columnas: {num_columnas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar 'FECHA' y 'HORA' en una nueva columna 'FECHA_HORA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hechos_df['HORA'] = hechos_df['HORA'].replace('SD', '00:00:00')\n",
    "\n",
    "\n",
    "# Verificar si la columna 'HORA' está en formato string y necesita conversión\n",
    "hechos_df['HORA'] = hechos_df['HORA'].apply(lambda x: x if isinstance(x, datetime.time) else pd.to_datetime(x).time())\n",
    "\n",
    "\n",
    "# Combinar 'FECHA' y 'HORA' en una nueva columna 'FECHA_HORA'\n",
    "hechos_df['FECHA_HORA'] = pd.to_datetime(hechos_df['FECHA'].astype(str) + ' ' + hechos_df['HORA'].astype(str), errors='coerce')\n",
    "\n",
    "# Verificar el resultado\n",
    "print(hechos_df[['FECHA', 'HORA', 'FECHA_HORA']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtrado = hechos_df.loc[hechos_df['pos x'] == '.']\n",
    "\n",
    "# Mostrar las filas filtradas\n",
    "print(filtrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las cordenadas en API google y llenar valores de valores con '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para obtener coordenadas usando la API de Google Maps\n",
    "def obtener_coordenadas(direccion, api_key):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={direccion}&key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    # Verificar si la solicitud fue exitosa y si hay resultados\n",
    "    if data['status'] == 'OK':\n",
    "        location = data['results'][0]['geometry']['location']\n",
    "        return location['lat'], location['lng']  # Retorna latitud y longitud\n",
    "    else:\n",
    "        # Retornar valores nulos si no se puede obtener la dirección\n",
    "        return None, None\n",
    "\n",
    "# Tu clave de API de Google Maps\n",
    "api_key = 'AIzaSyDyVSvFu2wxYivarcLCGU1wYrE51U-CroA'\n",
    "\n",
    "# Iterar sobre las filas del DataFrame original y actualizar 'pos x' y 'pos y'\n",
    "for index, row in hechos_df.iterrows():\n",
    "    if row['pos x'] == '.':  # Solo procesar si 'pos x' es igual a '.'\n",
    "        direccion = row['LUGAR_DEL_HECHO']\n",
    "\n",
    "        if pd.notnull(direccion):  # Solo buscar si la dirección no es nula\n",
    "            lat, lng = obtener_coordenadas(direccion, api_key)\n",
    "            \n",
    "            # Reemplazar los valores en 'pos x' y 'pos y' en el DataFrame original\n",
    "            hechos_df.at[index, 'pos y'] = lat\n",
    "            hechos_df.at[index, 'pos x'] = lng\n",
    "        else:\n",
    "            # Si no hay dirección, dejar los valores actuales\n",
    "            hechos_df.at[index, 'pos x'] = None\n",
    "            hechos_df.at[index, 'pos y'] = None\n",
    "\n",
    "#Se eliminan nos valores nulos \n",
    "hechos_df = hechos_df.dropna(subset=['pos x', 'pos y'])\n",
    "\n",
    "# Mostrar el DataFrame actualizado\n",
    "print(hechos_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar columnas redundantes e innecesarias en hechos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir las columnas a eliminar\n",
    "columnas_a_eliminar = ['AAAA', 'MM', 'DD','HH','Calle','Altura', 'Cruce', 'Dirección Normalizada','XY (CABA)', 'HORA','FECHA','LUGAR_DEL_HECHO']\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "hechos_df = hechos_df.drop(columns=columnas_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISAR LOS VALORES UNICOS DE CADA COLUMNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una lista de columnas para las cuales deseas obtener valores únicos\n",
    "columnas_a_consultar = ['VICTIMA', 'CALLE',  'ACUSADO']  # Puedes modificar esta lista\n",
    "\n",
    "# Obtener los valores únicos de las columnas especificadas en hechos_df\n",
    "unique_values = {col: hechos_df[col].unique() for col in columnas_a_consultar if col in hechos_df.columns}\n",
    "\n",
    "# Mostrar los valores únicos para cada columna especificada\n",
    "for column, unique_values in unique_values.items():\n",
    "    print(f\"Valores únicos en la columna '{column}':\\n{unique_values}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir las columnas pos x y pos y en tipo float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores no válidos (por ejemplo, \".\") por NaN\n",
    "hechos_df['pos x'] = hechos_df['pos x'].replace('.', np.nan)\n",
    "hechos_df['pos y'] = hechos_df['pos y'].replace('.', np.nan)\n",
    "\n",
    "# Convertir las columnas a tipo numérico (float), forzando el manejo de errores\n",
    "hechos_df['pos x'] = pd.to_numeric(hechos_df['pos x'], errors='coerce')\n",
    "hechos_df['pos y'] = pd.to_numeric(hechos_df['pos y'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERIFICAR COLUMNA FECHA_HORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar los valores nulos en la columna 'FECHA_HORA' del DataFrame 'hechos_df'\n",
    "nulos_fecha_hora = hechos_df['FECHA_HORA'].isnull().sum()\n",
    "valores_nulos_fecha_hora = hechos_df['FECHA_HORA'].isnull()\n",
    "\n",
    "# Mostrar la cantidad de valores nulos y los registros donde están presentes\n",
    "valores_nulos_info = hechos_df[valores_nulos_fecha_hora]\n",
    "\n",
    "nulos_fecha_hora, valores_nulos_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de siniestros por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraer el año de la columna FECHA y crear la nueva columna 'AAAA'\n",
    "hechos_df['AÑO'] = hechos_df['FECHA_HORA'].dt.year\n",
    "\n",
    "# Ejemplo gráfico: cantidad de siniestros por año\n",
    "siniestros_por_ano = hechos_df.groupby('AÑO').size()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "siniestros_por_ano.plot(kind='bar', color='lightcoral')\n",
    "plt.title('Cantidad de siniestros por año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Número de siniestros')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar columnas redundantes e innecesarias en victimas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas a eliminar\n",
    "columnas_a_eliminar = ['AAAA', 'MM', 'DD','FECHA_FALLECIMIENTO','FECHA']\n",
    "\n",
    "# Eliminar las columnas del DataFrame\n",
    "victimas_df = victimas_df.drop(columns=columnas_a_eliminar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de Datos en victimas_df y modificacion del formato de Fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los valores \"SD\" en la columna EDAD por 0 \n",
    "victimas_df['EDAD'] = np.where(victimas_df['EDAD'] == 'SD', 0, victimas_df['EDAD'])\n",
    "\n",
    "# Convertir la columna EDAD a tipo numérico\n",
    "victimas_df['EDAD'] = pd.to_numeric(victimas_df['EDAD'], errors='coerce').fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmar Valores Unicos de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores únicos en victimas_df\n",
    "roles_victimas = victimas_df['ROL'].unique()\n",
    "victimas_victimas = victimas_df['VICTIMA'].unique()\n",
    "sexos_victimas = victimas_df['SEXO'].unique()\n",
    "\n",
    "print(\"Roles en victimas_df:\", roles_victimas)\n",
    "print(\"Victimas en victimas_df:\", victimas_victimas)\n",
    "print(\"Sexos en victimas_df:\", sexos_victimas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gráfico para la distribución de la edad de las víctimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la distribución de la edad de las víctimas\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Creamos un histograma de las edades\n",
    "sns.histplot(victimas_df['EDAD'], bins=15, kde=True, color='skyblue')\n",
    "plt.title('Distribución de la Edad de las Víctimas en Siniestros Viales')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CANTIDAD TOTAL POR TIPO DE CALLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico para la variable cualitativa 'TIPO_DE_CALLE'\n",
    "sns.countplot(data=hechos_df, x='TIPO_DE_CALLE', palette='viridis')\n",
    "plt.title('Cantidad de Siniestros Viales por Tipo de Calle')\n",
    "plt.xlabel('Tipo de Calle')\n",
    "plt.ylabel('Cantidad de Siniestros')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representacion grafica Número de Siniestros Viales por Comuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agrupar por comuna y contar los siniestros\n",
    "siniestros_por_comuna = hechos_df['COMUNA'].value_counts()\n",
    "\n",
    "# Crear un gráfico de barras para siniestros por comuna\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=siniestros_por_comuna.index, y=siniestros_por_comuna.values, palette='viridis')\n",
    "plt.title('Número de Siniestros Viales por Comuna')\n",
    "plt.xlabel('Comuna')\n",
    "plt.ylabel('Cantidad de Siniestros')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE HECHOS_CV A MYSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Cargar el DataFrame hechos_df (asegúrate de que lo hayas definido previamente)\n",
    "# hechos_df = pd.read_excel('tu_archivo.xlsx', sheet_name='tu_hoja')  # Ejemplo para cargar datos\n",
    "\n",
    "# Parámetros de conexión\n",
    "host = '6.tcp.ngrok.io'\n",
    "user = 'root'\n",
    "port = '13979'\n",
    "password = 'Colombia1717.'\n",
    "database = 'Proyecto2'\n",
    "\n",
    "# Crear una conexión a la base de datos utilizando SQLAlchemy\n",
    "connection_string = f'mysql+mysqlconnector://{user}:{password}@{host}:{port}/{database}'\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "\n",
    "# Intentar subir el DataFrame a la tabla 'hechos'\n",
    "try:\n",
    "    hechos_df.to_sql('hechos', con=engine, if_exists='append', index=False)\n",
    "    print(\"Datos de hechos insertados exitosamente.\")\n",
    "\n",
    "    # Verificar si ID_hecho existe en hechos\n",
    "    existing_ids = hechos_df['ID'].unique()  # Obtener IDs existentes en hechos\n",
    "    victimas_df = victimas_df[victimas_df['ID_hecho'].isin(existing_ids)]  # Filtrar victimas_df\n",
    "\n",
    "    # Subir el DataFrame a la tabla 'victimas'\n",
    "    if not victimas_df.empty:\n",
    "        victimas_df.to_sql('victimas', con=engine, if_exists='append', index=False)\n",
    "        print(\"Datos de victimas insertados exitosamente.\")\n",
    "    else:\n",
    "        print(\"No hay datos de victimas para insertar.\");\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Ocurrió un error durante la inserción:\", str(e))\n",
    "\n",
    "finally:\n",
    "    # Cerrar la conexión\n",
    "    engine.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
